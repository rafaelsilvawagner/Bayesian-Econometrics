########################################################################################################################################
############################################################LOAD PACKAGES###############################################################
########################################################################################################################################


require(xts)
require(TStools)
require(tsDyn)
require(data.table)
require(highfrequency)
library(caret)
require(forecast)
require(RWeka)
require(randomGLM)
require(Cubist)
require(colf)
require(keras)
require(xgboost)
require(MCS)
require(glmnet)
require(timeSeries)
require(MASS)
require(Rsolnp)
require(foreach)
require(doParallel)
require(mvtnorm)
require(rnn)
require(glmc)
require(doParallel)
require(parcor)



########################################################################################################################################
############################################################PREPARE THE DATA############################################################
########################################################################################################################################

#Asset tickers
assets<-c("AAPL","EBAY","GS","MSFT","PG","ABT","BAC","CVX","GE","CAT")

#Let's make the first asset RV
data <- read.table(sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//%s.txt",assets[1]), header = TRUE, sep = ',', dec = '.')
date<- as.POSIXct(paste(data$Date, data$Time), format="%m/%d/%Y %H:%M")
xts <- xts(data[,-1], order.by=date)
realizedVar<-rCov(xts$Close,cor = FALSE, align.by = 'minutes', #YOU'LL ANALIXE 5 MIN REALIZED VARIANCE
                  align.period = 5,   makeReturns = TRUE)
index(realizedVar)<-as.Date(index(realizedVar))#like all xts objects make a index




#take a look in your frame
#View(realizedVar)

#Make the same procedure for all the assets defined in the assets frame
for(asset in assets[-1]){
  data <- read.table(sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//%s.txt",asset), header = TRUE, sep = ',', dec = '.')
  date<- as.POSIXct(paste(data$Date, data$Time), format="%m/%d/%Y %H:%M")
  xts <- xts(data[,-1], order.by=date)
  realized<-rCov(xts$Close,cor = FALSE, align.by = 'minutes', 
                 align.period = 5,   makeReturns = TRUE)
  index(realized)<-as.Date(index(realized))
  
  realizedVar<-merge.xts(realizedVar,realized, join='inner')
}

colnames(realizedVar)<-assets

#Pay attention, we will analyze the log of realizedVar
realizedVar<-log((realizedVar))
forecasts_1step<-list()
forecasts_5step<-list()


########################################################################################################################################
#############################################################FREQUENTIST STUFF##########################################################
########################################################################################################################################

#You'll do everything for all assets
for(asset in 1:10){
  Var<-realizedVar[,asset]
  reg<-cbind(Var,matrix(0,nrow=nrow(Var),ncol=22))
  lags<-matrix(nrow=nrow(reg),ncol=22)
  lags<-as.xts(lags,order.by=index(Var))
  
  for(i in 1:22){
    lags[,i]<-lag(Var,i)
  }
  
  #create Mean Lags
  for(j in 2:23){
    reg[,j]<-rowMeans(lags[,1:(j-1)],na.rm=FALSE)
  }
  
  reg<-reg[23:nrow(reg),]
  reg_1<-reg
  reg_5<-cbind(timeSeries::lag(reg[,1],-4),reg[1:(nrow(reg)-4),-1])
  
  #give lags names
  colnames(reg_1)<-c('Close',paste("Close.",1:22,sep=""))
  colnames(reg_5)<-c('Close',paste("Close.",6:27,sep=""))
  reg_5<-reg_5[1:(nrow(reg_5)-4),]
  index(reg_5)<-index(reg_1)[5:nrow(reg_1)]
  
  #Create matrix to store the results
  models<-8
  
  initial_sample_1<-round(0.8*nrow(reg_1))
  total_forecasts_1<-nrow(reg_1)-initial_sample_1
  
  
  predicted_1step<-matrix(NA,nrow=total_forecasts_1,ncol=(models+1))
  predicted_1step<-xts(x=predicted_1step,order.by=index(reg_1)[(initial_sample_1+1):(nrow(reg_1))])
  
  initial_sample_5<-round(0.8*nrow(reg_5))
  total_forecasts_5<-nrow(reg_5)-initial_sample_5
  
  predicted_5step<-matrix(NA,nrow=total_forecasts_5,ncol=(models+1))
  predicted_5step<-xts(x=predicted_5step,order.by=index(reg_5)[(initial_sample_5+1):(nrow(reg_5))])
  
  
  colnames(predicted_1step)<-c("Realized","HAR","Lasso","Adalasso",
                               "M5P","Bagging","Cubist",
                               "Bayes_Sin","Bayes_exp")
  
  colnames(predicted_5step)<-c("Realized","HAR","Lasso","Adalasso",
                               "M5P","Bagging","Cubist",
                               "Bayes_Sin","Bayes_exp")
 
  for(ri in initial_sample_1:(nrow(reg_1)-1)){
    print(paste("Asset",asset,"Rounds Left",(nrow(reg_1)-1)-ri,"1-step ahead"))
    
    ################################################################################################################################
    #################################################PREVISÕES 1 PASSO##############################################################
    ################################################################################################################################
    
    #In the first day store the realized
    if(ri==initial_sample_1){
      predicted_1step[,1]<-exp(reg_1[(initial_sample_1+1):(nrow(reg_1)),1])
    }
    
    #Select the data to train
    yx<-(reg_1[(ri+1-initial_sample_1):ri, ])
    #Separate the regressors
    x<-(reg_1[(ri+1-initial_sample_1):ri,-1])
    #Separate the response
    y<-(reg_1[(ri+1-initial_sample_1):ri, 1])
    
    ######################
    ####Linear Frequentist
    ######################
    
    #HAR
    har<-lm(Close~Close.1+Close.5+Close.22,data = yx)
    #Lasso
    cv.out <- cv.glmnet(x=as.matrix(x), y=as.matrix(y), alpha=1)
    lasso.mod <- glmnet(x=as.matrix(x), y=as.matrix(y), lambda=cv.out$lambda.1se,alpha=1)
    #Adalasso
    adalasso<-parcor::adalasso(X=as.matrix(x),y=as.matrix(y),intercept=TRUE,both=TRUE)
    
    ######################
    ####Tree Based Methods
    ######################
    
    #M5P
    M5_model = RWeka::M5P(Close ~ ., data = yx,control=Weka_control(N=F,U=F,R=F))
    #BAGGING
    M5_bag = Bagging(Close ~ ., data = yx,control = Weka_control(P=100,I=500,W=list("weka.classifiers.trees.M5P", N=F,U=T,R=F,M=10)))
    #CUBIST
    cube<-cubist(x=as.matrix(x),y=as.matrix(y),committees=5, neighbors=5)
    
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    
    #CÓDIGOS BEYSIANOS
    
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    
    ######################
    ####Prior HAR
    ######################
    if(ri==initial_sample_1){
      train<-0.9
      test<-0.1
      loops<-round(test*nrow(yx))
      
      strong1<-10^(-seq(1,15))
      strong2<-10^(-seq(1,15))
      loopgrid<-expand.grid(strong1,strong2)
      loopgrid<-cbind(loopgrid,0)
      colnames(loopgrid)<-c("strong1","strong2","MSE")
      
      errou_har<-matrix(0,ncol=nrow(loopgrid),nrow=loops)
      
      B0<-rep(0,23)
      B0[c(2,6,23)]<-0.3
      B0[c(1)]<-0.01
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(0.2,0.2,rep(loopgrid[bayhat,1],3),0.2,rep(loopgrid[bayhat,2],16),0.2)
        
        for(tr in 1:loops){
          index_train<-tr:(nrow(yx)-loops+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_har[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_har))
      V0_sin<-c(0.2,0.2,rep(loopgrid[min,1],3),0.2,rep(loopgrid[min,2],16),0.2)
      loopgrid[,3]<-colSums(errou_har)
      write.csv(loopgrid,sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Bayesian Estimation//Priori Har Ativo %s freq 1.csv",asset))
      
    } else {
      
      strong1<-10^(-seq(1,15))
      strong2<-10^(-seq(1,15))
      loopgrid<-expand.grid(strong1,strong2)
      loopgrid<-cbind(loopgrid,0)
      colnames(loopgrid)<-c("strong1","strong2","MSE")
      
      
      errou_har[1:(loops-1),]<-errou_har[2:(loops),]
      
      
      B0<-rep(0,23)
      B0[c(2,6,23)]<-0.3
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(0.2,0.2,rep(loopgrid[bayhat,1],3),0.2,rep(loopgrid[bayhat,2],16),0.2)
        
        for(tr in loops){
          index_train<-tr:(nrow(yx)-round(test*nrow(yx))+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_har[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_har))
      V0_sin<-c(0.2,0.2,rep(loopgrid[min,1],3),0.2,rep(loopgrid[min,2],16),0.2)
    }
    
    #Make the bayesian estimation
    B0<-rep(0,23)
    B0[c(2,6,23)]<-0.3
    x_bayes<-cbind(1,x)
    bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y
    V1<-solve(diag(1/V0_sin)+t(x_bayes)%*%x_bayes)
    B1_SIN<-V1%*%(diag(1/V0_sin)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
    
    ######################
    ####Prior Exp
    ######################
    
    if(ri==initial_sample_1){
      
      B0<-rep(0,23)
      par1<-1:5
      par2<-1/(1:10)
      Var<-1:22
      loopgrid<-cbind(expand.grid(par1,par2),NA)
      colnames(loopgrid)<-c("par1","par2","MSE")
      
      errou_exp<-matrix(0,ncol=nrow(loopgrid),nrow=loops)
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(1,(seq(loopgrid[bayhat,2],0,-loopgrid[bayhat,2]/22)[1:22])^loopgrid[bayhat,1])
        
        for(tr in 1:loops){
          index_train<-tr:(nrow(yx)-round(test*nrow(yx))+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_exp[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_exp))
      V0_exp<-c(1,(seq(loopgrid[min,2],0,-loopgrid[min,2]/22)[1:22])^loopgrid[min,1])
      loopgrid[,3]<-colSums(errou_exp)
      write.csv(loopgrid,sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Bayesian Estimation//Priori Exp Ativo %s freq 1.csv",asset))
    } else {
      errou_exp[1:(loops-1),]<-errou_exp[2:(loops),]
      
      B0<-rep(0,23)
      par1<-1:5
      par2<-1/(1:10)
      Var<-1:22
      loopgrid<-cbind(expand.grid(par1,par2),NA)
      colnames(loopgrid)<-c("par1","par2","MSE")
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(1,(seq(loopgrid[bayhat,2],0,-loopgrid[bayhat,2]/22)[1:22])^loopgrid[bayhat,1])
        
        for(tr in loops){
          index_train<-tr:(nrow(yx)-round(test*nrow(yx))+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_exp[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_exp))
      V0_exp<-c(1,(seq(loopgrid[min,2],0,-loopgrid[min,2]/22)[1:22])^loopgrid[min,1])
    }
    
    #Make the bayesian estimation
    B0<-rep(0,23)
    x_bayes<-cbind(1,x)
    bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y
    V1<-solve(diag(1/V0_exp)+t(x_bayes)%*%x_bayes)
    B1_EXP<-V1%*%(diag(1/V0_exp)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
    
    
    ######################
    ####Forecasts
    ######################
    
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),2] = exp(predict(har, (reg_1[(ri+1),])))
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),3] = exp(predict(lasso.mod, as.matrix((reg_1[(ri+1),-1]))))
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),4] = exp(adalasso$intercept.adalasso+sum(adalasso$coefficients.adalasso*reg_1[(ri+1),-1]))
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),5] = exp(predict(M5_model, (reg_1[(ri+1),])))
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),6] = exp(predict(M5_bag, (reg_1[(ri+1),])))
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),7] = exp(predict(cube, as.matrix((reg_1[(ri+1),-1]))))
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),8] = exp((c(1,matrix(reg_1[(ri+1),-1]))%*%B1_SIN))
    predicted_1step[(ri-round(0.8*nrow(reg_1))+1),9] = exp((c(1,matrix(reg_1[(ri+1),-1]))%*%B1_EXP))
    
    
    in_sample<-matrix(0,ncol=models+1,nrow=initial_sample_1)
    colnames(in_sample)<-colnames(predicted_1step)
    
    in_sample[,1]<-exp(y) 
    in_sample[,2]<-exp((predict(har, (reg_1[(ri+1-initial_sample_1):ri,]))))
    in_sample[,3]<-exp((predict(lasso.mod, as.matrix((reg_1[(ri+1-initial_sample_1):ri,-1])))))
    in_sample[,4]<-exp(adalasso$intercept.adalasso+reg_1[(ri+1-initial_sample_1):ri,-1]%*%adalasso$coefficients.adalasso)
    in_sample[,5]<-exp((predict(M5_model, (reg_1[(ri+1-initial_sample_1):ri,]))))
    in_sample[,6]<-exp((predict(M5_bag, (reg_1[(ri+1-initial_sample_1):ri,]))))
    in_sample[,7]<-exp((predict(cube, (reg_1[(ri+1-initial_sample_1):ri,]))))
    in_sample[,8]<-exp(((as.matrix(cbind(1,reg_1[(ri+1-initial_sample_1):ri,-1])))%*%B1_SIN))
    in_sample[,9]<-exp(((as.matrix(cbind(1,reg_1[(ri+1-initial_sample_1):ri,-1])))%*%B1_EXP))

    
    write.csv(in_sample,
              sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Models Forecasts//In Sample//1 minute//Asset %s round %s.csv",
                      asset,ri))
  }
  write.csv(predicted_1step,
            sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Models Forecasts//Out Sample//1 minute//Asset %s.csv",
                    asset))
  
  for(ri in initial_sample_5:(nrow(reg_5)-1)){
    print(paste("Asset",asset,"Round",(nrow(reg_5)-1)-ri,"5-step ahead"))
    
    ################################################################################################################################
    #################################################PREVISÕES 1 PASSO##############################################################
    ################################################################################################################################
    
    #In the first day store the realized
    if(ri==initial_sample_5){
      predicted_5step[,1]<-exp(reg_5[(initial_sample_5+1):(nrow(reg_5)),1])
    }
    
    #Select the data to train
    yx<-(reg_5[(ri+1-initial_sample_5):ri, ])
    #Separate the regressors
    x<-(reg_5[(ri+1-initial_sample_5):ri,-1])
    #Separate the response
    y<-(reg_5[(ri+1-initial_sample_5):ri, 1])
    
    ######################
    ####Linear Frequentist
    ######################
    
    #HAR
    har<-lm(Close~Close.6+Close.10+Close.27,data = yx)
    #Lasso
    cv.out <- cv.glmnet(x=as.matrix(x), y=as.matrix(y), alpha=1)
    lasso.mod <- glmnet(x=as.matrix(x), y=as.matrix(y), lambda=cv.out$lambda.1se,alpha=1)
    #Adalasso
    adalasso<-parcor::adalasso(X=as.matrix(x),y=as.matrix(y),intercept=TRUE,both=TRUE)
    
    ######################
    ####Tree Based Methods
    ######################
    
    #M5P
    M5_model = RWeka::M5P(Close ~ ., data = yx,control=Weka_control(N=F,U=F,R=F))
    #BAGGING
    M5_bag = Bagging(Close ~ ., data = yx,control = Weka_control(P=100,I=500,W=list("weka.classifiers.trees.M5P", N=F,U=T,R=F,M=10)))
    #CUBIST
    cube<-cubist(x=as.matrix(x),y=as.matrix(y),committees=5, neighbors=5)
    
 
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    
    #BAYSIAN
    
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    ##################################################################################################################
    
    ######################
    ####Prior HAR
    ######################
    
    if(ri==initial_sample_5){
      train<-0.9
      test<-0.1
      loops<-round(test*nrow(yx))
      
      strong1<-10^(-seq(1,15))
      strong2<-10^(-seq(1,15))
      loopgrid<-expand.grid(strong1,strong2)
      loopgrid<-cbind(loopgrid,0)
      colnames(loopgrid)<-c("strong1","strong2","MSE")
      
      errou_har<-matrix(0,ncol=nrow(loopgrid),nrow=loops)
      
      B0<-rep(0,23)
      B0[c(2,6,23)]<-0.3
      B0[c(1)]<-0.01
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(0.2,0.2,rep(loopgrid[bayhat,1],3),0.2,rep(loopgrid[bayhat,2],16),0.2)
        
        for(tr in 1:loops){
          index_train<-tr:(nrow(yx)-round(test*nrow(yx))+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_har[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_har))
      V0_sin<-c(0.2,0.2,rep(loopgrid[min,1],3),0.2,rep(loopgrid[min,2],16),0.2)
      loopgrid[,3]<-colSums(errou_har)
      write.csv(loopgrid,sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Bayesian Estimation//Priori Har Ativo %s freq 5.csv",asset))
    } else {
      
      strong1<-10^(-seq(1,15))
      strong2<-10^(-seq(1,15))
      loopgrid<-expand.grid(strong1,strong2)
      loopgrid<-cbind(loopgrid,0)
      colnames(loopgrid)<-c("strong1","strong2","MSE")
      
      
      errou_har[1:(loops-1),]<-errou_har[2:(loops),]
      
      
      B0<-rep(0,23)
      B0[c(2,6,23)]<-0.3
      B0[c(1)]<-0.01
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(0.2,0.2,rep(loopgrid[bayhat,1],3),0.2,rep(loopgrid[bayhat,2],16),0.2)
        
        for(tr in loops){
          index_train<-tr:(nrow(yx)-round(test*nrow(yx))+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_har[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_har))
      V0_sin<-c(0.2,0.2,rep(loopgrid[min,1],3),0.2,rep(loopgrid[min,2],16),0.2)
    }
    
    #Make the bayesian estimation
    B0<-rep(0,23)
    B0[c(2,6,23)]<-0.3
    B0[c(1)]<-0.01
    x_bayes<-cbind(1,x)
    bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y
    V1<-solve(diag(1/V0_sin)+t(x_bayes)%*%x_bayes)
    B1_SIN<-V1%*%(diag(1/V0_sin)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
    
    ######################
    ####Prior Exp
    ######################
    
    if(ri==initial_sample_5){
      
      B0<-rep(0,23)
      par1<-1:5
      par2<-1/(1:10)
      Var<-1:22
      loopgrid<-cbind(expand.grid(par1,par2),NA)
      colnames(loopgrid)<-c("par1","par2","MSE")
      
      errou_exp<-matrix(0,ncol=nrow(loopgrid),nrow=loops)
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(1,(seq(loopgrid[bayhat,2],0,-loopgrid[bayhat,2]/22)[1:22])^loopgrid[bayhat,1])
        
        for(tr in 1:loops){
          index_train<-tr:(nrow(yx)-round(test*nrow(yx))+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_exp[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_exp))
      V0_exp<-c(1,(seq(loopgrid[min,2],0,-loopgrid[min,2]/22)[1:22])^loopgrid[min,1])
      loopgrid[,3]<-colSums(errou_exp)
      write.csv(loopgrid,sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Bayesian Estimation//Priori Exp Ativo %s freq 5.csv",asset))
    } else {
      errou_exp[1:(loops-1),]<-errou_exp[2:(loops),]
      
      B0<-rep(0,23)
      par1<-1:5
      par2<-1/(1:10)
      Var<-1:22
      loopgrid<-cbind(expand.grid(par1,par2),NA)
      colnames(loopgrid)<-c("par1","par2","MSE")
      
      for(bayhat in 1:nrow(loopgrid)){
        #Training Data
        V0<-c(1,(seq(loopgrid[bayhat,2],0,-loopgrid[bayhat,2]/22)[1:22])^loopgrid[bayhat,1])
        
        for(tr in loops){
          index_train<-tr:(nrow(yx)-round(test*nrow(yx))+tr-1)
          x_train<-yx[index_train,-1]
          y_train<-yx[index_train,1]
          x_test<-yx[last(index_train)+1,-1]
          y_test<-yx[last(index_train)+1,1]
          
          x_bayes<-cbind(1,x_train)
          bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y_train
          V1<-solve(diag(1/V0)+t(x_bayes)%*%x_bayes)
          B1<-V1%*%(diag(1/V0)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
          
          loopforecast<-cbind(1,x_test)%*%B1
          errou_exp[tr,bayhat]<-(loopforecast-y_test)^2
        }
      }
      min<-which.min(colSums(errou_exp))
      V0_exp<-c(1,(seq(loopgrid[min,2],0,-loopgrid[min,2]/22)[1:22])^loopgrid[min,1])
    }
    
    #Make the bayesian estimation
    B0<-rep(0,23)
    x_bayes<-cbind(1,x)
    bols<-solve(t(x_bayes)%*%x_bayes)%*%t(x_bayes)%*%y
    V1<-solve(diag(1/V0_exp)+t(x_bayes)%*%x_bayes)
    B1_EXP<-V1%*%(diag(1/V0_exp)%*%B0+t(x_bayes)%*%x_bayes%*%bols)
    ######################
    ####Forecasts
    ######################
    
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),2] = exp(predict(har, (reg_5[(ri+1),])))
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),3] = exp(predict(lasso.mod, as.matrix((reg_5[(ri+1),-1]))))
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),4] = exp(adalasso$intercept.adalasso+sum(adalasso$coefficients.adalasso*reg_5[(ri+1),-1]))
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),5] = exp(predict(M5_model, (reg_5[(ri+1),])))
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),6] = exp(predict(M5_bag, (reg_5[(ri+1),])))
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),7] = exp(predict(cube, as.matrix((reg_5[(ri+1),-1]))))
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),8] = exp((c(1,matrix(reg_5[(ri+1),-1]))%*%B1_SIN))
    predicted_5step[(ri-round(0.8*nrow(reg_5))+1),9] = exp((c(1,matrix(reg_5[(ri+1),-1]))%*%B1_EXP))
    
    
    in_sample<-matrix(0,ncol=models+1,nrow=initial_sample_5)
    colnames(in_sample)<-colnames(predicted_5step)
    
    in_sample[,1]<-exp(y) 
    in_sample[,2]<-exp((predict(har, (reg_5[(ri+1-initial_sample_5):ri,]))))
    in_sample[,3]<-exp((predict(lasso.mod, as.matrix((reg_5[(ri+1-initial_sample_5):ri,-1])))))
    in_sample[,4]<-exp(adalasso$intercept.adalasso+reg_5[(ri+1-initial_sample_5):ri,-1]%*%adalasso$coefficients.adalasso)
    in_sample[,5]<-exp((predict(M5_model, (reg_5[(ri+1-initial_sample_5):ri,]))))
    in_sample[,6]<-exp((predict(M5_bag, (reg_5[(ri+1-initial_sample_5):ri,]))))
    in_sample[,7]<-exp((predict(cube, (reg_5[(ri+1-initial_sample_5):ri,]))))
    in_sample[,8]<-exp(((as.matrix(cbind(1,reg_5[(ri+1-initial_sample_5):ri,-1])))%*%B1_SIN))
    in_sample[,9]<-exp(((as.matrix(cbind(1,reg_5[(ri+1-initial_sample_5):ri,-1])))%*%B1_EXP))
    
    write.csv(in_sample,
              sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Models Forecasts//In Sample//5 minutes//Asset %s round %s.csv",
                      asset,ri))
  }
  write.csv(predicted_5step,
            sprintf("C://Users//Usuario//Desktop//Rafael - Dissertacao//Realized Variance//Models Forecasts//Out Sample//5 minutes//Asset %s.csv",
                    asset))
}
